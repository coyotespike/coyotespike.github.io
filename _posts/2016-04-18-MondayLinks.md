---
layout: post
title: Monday Links
date: 2016-04-18 12:01
# Should be longer than 150 words, so it will appear as post summary
description: "A few papers highlighted on Andrew Gelman's blog. File under 'how to fix science'."
# tags will also be used as html meta keywords.
tags:
  - synthetic biology

show_meta: true
comments: true
mathjax: true
gistembed: true
published: true
noindex: false
nofollow: false
---

<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgheadline1">1. Born-Open Data</a></li>
<li><a href="#orgheadline2">2. Scientific Utopia I and II.</a></li>
<li><a href="#orgheadline3">3. Synthetic biology and open data</a></li>
</ul>
</div>
</div>

### Born-Open Data

First up, we have Jeffrey Rouder on [born-open data](http://pcl.missouri.edu/sites/default/files/r_1.pdf), his phrase for what software engineers call "open source."
Most scientists make their data available-on-demand in theory, less so in practice. Rouder realized that he would
never live up to his own data-distribution expecations if his lab had to do it manually - so now his lab has a simple
shell script that backs up his data to GitHub nightly.

Rouder also addresses common concerns over making data available pre-publication. In particular, he argues that 
data without the article isn't as susceptible to scientific plagiarism as many fear.

### [Scientific Utopia I](http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2051047) and [II](http://pps.sagepub.com/content/7/6/615.full).

This is a wonderful pair of articles on how to improve scientific standards. The authors recount their tale of "losing"
a promising result by performing a direct replication before publishing it - only to see the result disappear!

They address the career incentives that push publication at the expense of accuracy, and make publication the end of the
research process. They argue that proposed fixes, such as journals devoted to replications and negative results or higher
editorial and review standards, won't fix the problem.

The ultimate solution is to open data, materials, and workflow.

### Synthetic biology and open data

Suppose you're just starting your scientific career (as I am). You might not have to worry about the academic job market.
What's the best way to advance the field? 

These articles suggest two things. First, more and more I get the impression that a working knowledge of statistics *far* 
higher than the average scientist possesses is a *sine qua non* of quality research. Like, do not pass go, do not collect
$200: do not perform research, do not publish, until you've done some hardcore statistics.

All sciences may not suffer from the same problems of replicability as do the social sciences, (I don't seem to read 
about this sort of thing in particle physics). Do we have the same problems in synthetic biology? I don't know, but John Ioannnidis 
and others have shown the same problem exists in the medical sciences. I'd therefore expect that other biosciences such as 
molecular biology may suffer from replicability issues.

Second, other scientists I've spoken to mentioned that data and techniques aren't adequately shared in the biosciences,
meaning you might not be able to replicate a result, not because the effect wasn't actually there, but because the published
article was not sufficiently open.

These articles argue forcefully that the best way to advance science is to practice post-publication peer review with fully
open data, materials, workflow, and techniques. Traditional publication should come second, at best.
