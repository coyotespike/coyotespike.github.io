---
layout: post
title: A Small Andrew Gelman Blog Library
date: 2016-04-23 22:49
# Should be longer than 20 words, so it will appear as post summary
description: The actual "Andrew Gelman Library" would have to include his books, articles, and Stan. Here's a collection of blog posts I enjoyed.
# tags will also be used as html meta keywords.
tags:
  - synthetic biology

show_meta: true
comments: true
mathjax: true
gistembed: true
published: true
noindex: false
nofollow: false
---

<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgheadline1">1. Statistics Done Wrong</a></li>
<li><a href="#orgheadline2">2. Differences between biology and statistics</a></li>
<li><a href="#orgheadline3">3. Gelman Quotes</a></li>
<li><a href="#orgheadline4">4. Handy Statistic Definitions</a></li>
<li><a href="#orgheadline5">5. The fault in our stars</a></li>
<li><a href="#orgheadline6">6. What Hypothesis Testing is All About</a></li>
<li><a href="#orgheadline7">7. How do data and experiments fit into a scientific research program?</a></li>
</ul>
</div>
</div>

The best thing about reading Andrew Gelman's blog is Andrew Gelman.

Like Tyler Cowen or Noahpinion, he's genuinely open to changing his mind - indeed, even eager to do so!
I've seen him do it in in the comments to his own post. While he frequently criticises folks who use trashy statistics,
he also thoughtfully considers the value their work might have, despite its lack of factual basis.

He comes across as an open, decent guy, with a sense of humor about himself, who's also written what looks like some of the best work in the field (Bayesian Data Analysis, Stan).

### [Statistics Done Wrong](http://www.statisticsdonewrong.com/)<a id="orgheadline1"></a>

Gelman links to this fun read on the most common statistical errors in science, since expanded into a book.

### [Differences between biology and statistics](http://andrewgelman.com/2014/02/20/differences-biology-statistics-explain-diverging-attitudes-regarding-criticism-replication-scientific-claims/)<a id="orgheadline2"></a>

Why have some biologists tried to start a backlash against the replication movement? Maybe it's something to do with the incentive structure.

### [Gelman Quotes](http://www.stat.columbia.edu/~gelman/book/gelman_quotes.pdf)<a id="orgheadline3"></a>

A collection of often-amusing quotations his students wrote down from his classes.

### [Handy Statistic Definitions](http://andrewgelman.com/2009/05/24/handy_statistic/)<a id="orgheadline4"></a>

A lot of good concepts to know, with links to helpful columns for every one!

### [The fault in our stars](http://andrewgelman.com/2014/10/15/fault-stars-even-worse-say/)<a id="orgheadline5"></a>

A significant result is often marked with an asterisk or star, hence the title.
On the abuse of statistics

### [What Hypothesis Testing is All About](http://andrewgelman.com/2015/03/02/what-hypothesis-testing-is-all-about-hint-its-not-what-you-think/)<a id="orgheadline6"></a>

Until reading this column, I still hadn't realized that most scientific statistics use the p-value to pull a judo move with Popperian falsification.
Most scientists play a game: make up a null hypothesis - whatever you want to disprove. Then, by failing to find data to support the null hypothesis,
you falsify it, and by disproving it, provide support for your new hypothesis.

Neat, huh? Gelman explains why disproving the p-value doesn't help you, but failing to disprove it does.

### [How do data and experiments fit into a scientific research program?](http://andrewgelman.com/2015/04/18/data-experiments-fit-scientific-research-program/)<a id="orgheadline7"></a>

What if someone builds a career out of a line of research that uses small sample sizes to make "progress"?
They'll keep finding spurious correlations, but earnestly believe they are doing good science.
Does this mean their work is useless? And what role is the data playing?
